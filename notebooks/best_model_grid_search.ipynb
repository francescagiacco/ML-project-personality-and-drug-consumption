{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4dde8463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Sklearn functions and models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import matthews_corrcoef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804750b7",
   "metadata": {},
   "source": [
    "## Logistic regression Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "77ab53bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt are the 3 drug types for which we run the models \n",
    "#select dt to choose drug type\n",
    "\n",
    "dt = 'hall_add_aggr'\n",
    "\n",
    "if dt not in ['hall_add_aggr','stim_add_aggr', 'depr_add_aggr','depr_woa_add_aggr','hall_woc_add_aggr'  ]:\n",
    "    raise ValueError('dt has to be one of: hall_add_aggr, stim_add_aggr, depr_add_aggr','depr_woa_add_aggr','hall_woc_add_aggr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3ac42426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>n_score</th>\n",
       "      <th>e_score</th>\n",
       "      <th>o_score</th>\n",
       "      <th>a_score</th>\n",
       "      <th>c_score</th>\n",
       "      <th>impulsiveness</th>\n",
       "      <th>ss</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>...</th>\n",
       "      <th>ireland</th>\n",
       "      <th>uk</th>\n",
       "      <th>usa</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>depr_add_aggr</th>\n",
       "      <th>depr_woa_add_aggr</th>\n",
       "      <th>hall_add_aggr</th>\n",
       "      <th>hall_woc_add_aggr</th>\n",
       "      <th>stim_add_aggr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.07854</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>0.40148</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>1.16365</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-1.19430</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>1.88511</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-1.13788</td>\n",
       "      <td>0.88113</td>\n",
       "      <td>1.92173</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.24649</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>0.58331</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-1.51840</td>\n",
       "      <td>0.88113</td>\n",
       "      <td>0.76540</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>-0.07854</td>\n",
       "      <td>0.45468</td>\n",
       "      <td>1.13281</td>\n",
       "      <td>-1.37639</td>\n",
       "      <td>-1.27553</td>\n",
       "      <td>-1.77200</td>\n",
       "      <td>-1.38502</td>\n",
       "      <td>0.52975</td>\n",
       "      <td>-0.52593</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>0.91093</td>\n",
       "      <td>-1.92173</td>\n",
       "      <td>0.29338</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-2.57309</td>\n",
       "      <td>1.29221</td>\n",
       "      <td>1.22470</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>2.12700</td>\n",
       "      <td>1.65653</td>\n",
       "      <td>1.11406</td>\n",
       "      <td>0.41594</td>\n",
       "      <td>0.88113</td>\n",
       "      <td>1.22470</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1885 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age  education  n_score  e_score  o_score  a_score  c_score  \\\n",
       "0     0.49788   -0.05921  0.31287 -0.57545 -0.58331 -0.91699 -0.00665   \n",
       "1    -0.07854    1.98437 -0.67825  1.93886  1.43533  0.76096 -0.14277   \n",
       "2     0.49788   -0.05921 -0.46725  0.80523 -0.84732 -1.62090 -1.01450   \n",
       "3    -0.95197    1.16365 -0.14882 -0.80615 -0.01928  0.59042  0.58489   \n",
       "4     0.49788    1.98437  0.73545 -1.63340 -0.45174 -0.30172  1.30612   \n",
       "...       ...        ...      ...      ...      ...      ...      ...   \n",
       "1880 -0.95197   -0.61113 -1.19430  1.74091  1.88511  0.76096 -1.13788   \n",
       "1881 -0.95197   -0.61113 -0.24649  1.74091  0.58331  0.76096 -1.51840   \n",
       "1882 -0.07854    0.45468  1.13281 -1.37639 -1.27553 -1.77200 -1.38502   \n",
       "1883 -0.95197   -0.61113  0.91093 -1.92173  0.29338 -1.62090 -2.57309   \n",
       "1884 -0.95197   -0.61113 -0.46725  2.12700  1.65653  1.11406  0.41594   \n",
       "\n",
       "      impulsiveness       ss  alcohol  ...  ireland  uk  usa  male  female  \\\n",
       "0          -0.21712 -1.18084        5  ...        0   1    0     0       1   \n",
       "1          -0.71126 -0.21575        5  ...        0   1    0     1       0   \n",
       "2          -1.37983  0.40148        6  ...        0   1    0     1       0   \n",
       "3          -1.37983 -1.18084        4  ...        0   1    0     0       1   \n",
       "4          -0.21712 -0.21575        4  ...        0   1    0     0       1   \n",
       "...             ...      ...      ...  ...      ...  ..  ...   ...     ...   \n",
       "1880        0.88113  1.92173        5  ...        0   0    1     0       1   \n",
       "1881        0.88113  0.76540        5  ...        0   0    1     1       0   \n",
       "1882        0.52975 -0.52593        4  ...        0   0    1     0       1   \n",
       "1883        1.29221  1.22470        5  ...        0   0    1     0       1   \n",
       "1884        0.88113  1.22470        4  ...        1   0    0     1       0   \n",
       "\n",
       "      depr_add_aggr  depr_woa_add_aggr  hall_add_aggr  hall_woc_add_aggr  \\\n",
       "0                 0                  0              0                  0   \n",
       "1                 0                  0              0                  0   \n",
       "2                 1                  0              0                  0   \n",
       "3                 0                  0              0                  0   \n",
       "4                 0                  0              0                  0   \n",
       "...             ...                ...            ...                ...   \n",
       "1880              1                  1              1                  1   \n",
       "1881              0                  0              2                  2   \n",
       "1882              2                  2              1                  0   \n",
       "1883              1                  1              2                  2   \n",
       "1884              0                  0              2                  2   \n",
       "\n",
       "      stim_add_aggr  \n",
       "0                 0  \n",
       "1                 1  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "...             ...  \n",
       "1880              0  \n",
       "1881              1  \n",
       "1882              2  \n",
       "1883              1  \n",
       "1884              2  \n",
       "\n",
       "[1885 rows x 48 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv('../data_processed/data_final_aggregates.csv')\n",
    "data.drop(columns = ['Unnamed: 0'], axis = 1, inplace = True)\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f6ea2898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>n_score</th>\n",
       "      <th>e_score</th>\n",
       "      <th>o_score</th>\n",
       "      <th>a_score</th>\n",
       "      <th>c_score</th>\n",
       "      <th>impulsiveness</th>\n",
       "      <th>ss</th>\n",
       "      <th>australia</th>\n",
       "      <th>...</th>\n",
       "      <th>new_zealand</th>\n",
       "      <th>ireland</th>\n",
       "      <th>uk</th>\n",
       "      <th>usa</th>\n",
       "      <th>female</th>\n",
       "      <th>depr_add_aggr</th>\n",
       "      <th>depr_woa_add_aggr</th>\n",
       "      <th>hall_add_aggr</th>\n",
       "      <th>hall_woc_add_aggr</th>\n",
       "      <th>stim_add_aggr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.07854</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>0.40148</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>1.16365</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-1.19430</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>1.88511</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-1.13788</td>\n",
       "      <td>0.88113</td>\n",
       "      <td>1.92173</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.24649</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>0.58331</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-1.51840</td>\n",
       "      <td>0.88113</td>\n",
       "      <td>0.76540</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>-0.07854</td>\n",
       "      <td>0.45468</td>\n",
       "      <td>1.13281</td>\n",
       "      <td>-1.37639</td>\n",
       "      <td>-1.27553</td>\n",
       "      <td>-1.77200</td>\n",
       "      <td>-1.38502</td>\n",
       "      <td>0.52975</td>\n",
       "      <td>-0.52593</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>0.91093</td>\n",
       "      <td>-1.92173</td>\n",
       "      <td>0.29338</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-2.57309</td>\n",
       "      <td>1.29221</td>\n",
       "      <td>1.22470</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>2.12700</td>\n",
       "      <td>1.65653</td>\n",
       "      <td>1.11406</td>\n",
       "      <td>0.41594</td>\n",
       "      <td>0.88113</td>\n",
       "      <td>1.22470</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1885 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age  education  n_score  e_score  o_score  a_score  c_score  \\\n",
       "0     0.49788   -0.05921  0.31287 -0.57545 -0.58331 -0.91699 -0.00665   \n",
       "1    -0.07854    1.98437 -0.67825  1.93886  1.43533  0.76096 -0.14277   \n",
       "2     0.49788   -0.05921 -0.46725  0.80523 -0.84732 -1.62090 -1.01450   \n",
       "3    -0.95197    1.16365 -0.14882 -0.80615 -0.01928  0.59042  0.58489   \n",
       "4     0.49788    1.98437  0.73545 -1.63340 -0.45174 -0.30172  1.30612   \n",
       "...       ...        ...      ...      ...      ...      ...      ...   \n",
       "1880 -0.95197   -0.61113 -1.19430  1.74091  1.88511  0.76096 -1.13788   \n",
       "1881 -0.95197   -0.61113 -0.24649  1.74091  0.58331  0.76096 -1.51840   \n",
       "1882 -0.07854    0.45468  1.13281 -1.37639 -1.27553 -1.77200 -1.38502   \n",
       "1883 -0.95197   -0.61113  0.91093 -1.92173  0.29338 -1.62090 -2.57309   \n",
       "1884 -0.95197   -0.61113 -0.46725  2.12700  1.65653  1.11406  0.41594   \n",
       "\n",
       "      impulsiveness       ss  australia  ...  new_zealand  ireland  uk  usa  \\\n",
       "0          -0.21712 -1.18084          0  ...            0        0   1    0   \n",
       "1          -0.71126 -0.21575          0  ...            0        0   1    0   \n",
       "2          -1.37983  0.40148          0  ...            0        0   1    0   \n",
       "3          -1.37983 -1.18084          0  ...            0        0   1    0   \n",
       "4          -0.21712 -0.21575          0  ...            0        0   1    0   \n",
       "...             ...      ...        ...  ...          ...      ...  ..  ...   \n",
       "1880        0.88113  1.92173          0  ...            0        0   0    1   \n",
       "1881        0.88113  0.76540          0  ...            0        0   0    1   \n",
       "1882        0.52975 -0.52593          0  ...            0        0   0    1   \n",
       "1883        1.29221  1.22470          0  ...            0        0   0    1   \n",
       "1884        0.88113  1.22470          0  ...            0        1   0    0   \n",
       "\n",
       "      female  depr_add_aggr  depr_woa_add_aggr  hall_add_aggr  \\\n",
       "0          1              0                  0              0   \n",
       "1          0              0                  0              0   \n",
       "2          0              1                  0              0   \n",
       "3          1              0                  0              0   \n",
       "4          1              0                  0              0   \n",
       "...      ...            ...                ...            ...   \n",
       "1880       1              1                  1              1   \n",
       "1881       0              0                  0              2   \n",
       "1882       1              2                  2              1   \n",
       "1883       1              1                  1              2   \n",
       "1884       0              0                  0              2   \n",
       "\n",
       "      hall_woc_add_aggr  stim_add_aggr  \n",
       "0                     0              0  \n",
       "1                     0              1  \n",
       "2                     0              0  \n",
       "3                     0              0  \n",
       "4                     0              0  \n",
       "...                 ...            ...  \n",
       "1880                  1              0  \n",
       "1881                  2              1  \n",
       "1882                  0              2  \n",
       "1883                  2              1  \n",
       "1884                  2              2  \n",
       "\n",
       "[1885 rows x 21 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substances = ['alcohol','anphet', 'amyl', 'benzo', 'caffeine', 'cannabis', \n",
    "              'chocolate', 'cocaine', 'crack', 'ecstasy', 'heroine', 'ketamine', \n",
    "              'legal_h', 'lsd', 'meth', 'mushrooms', 'nicotine', 'semer', 'vsa', 'male']\n",
    "\n",
    "nationality = ['australia', 'canada', 'new_zealand', 'ireland', 'uk', 'usa']\n",
    "\n",
    "race = ['asian', 'black_asian', 'white_asian','white_black', 'other', 'white', 'other2']\n",
    "\n",
    "data.drop(columns=substances + race, inplace=True, axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "72e42965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Stimulants mutual information')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# where more information is stored (I think, does someone know it better?)\n",
    "\n",
    "data[dt].replace(2,1, inplace = True) #just 2 classes not three\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(columns = ['hall_add_aggr','stim_add_aggr', 'depr_add_aggr','depr_woa_add_aggr','hall_woc_add_aggr'], axis=1), \n",
    "                                                    data[dt], test_size=0.25, random_state=0)\n",
    "\n",
    "mi = mutual_info_classif(X_train, y_train)\n",
    "mi = pd.Series(mi)\n",
    "mi.index = X_train.columns\n",
    "mi.sort_values(ascending=False).plot.bar(figsize=(30, 6))\n",
    "plt.ylabel('Mutual Information')\n",
    "plt.title('Stimulants mutual information')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f61b337a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    848\n",
       "1    848\n",
       "Name: hall_add_aggr, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "oversample = SMOTE()\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "y_train.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cc43df24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_scorer(matthews_corrcoef)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "MCC_scorer = make_scorer(matthews_corrcoef)\n",
    "MCC_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2ba68f9f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hyperparameters :(best parameters)  {'C': 0.09, 'penalty': 'l1', 'solver': 'saga'}\n",
      "MCC : 0.6276084962309758\n",
      "Running time: 19.943482637405396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "160 fits failed out of a total of 600.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Francesca\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.62284702 0.62284702        nan 0.62284702 0.62284702        nan\n",
      "        nan 0.                nan 0.         0.59719089 0.59719089\n",
      " 0.59463701 0.59719089 0.59719089 0.62284702 0.62284702        nan\n",
      " 0.62284702 0.62284702        nan        nan 0.57032843        nan\n",
      " 0.58079106 0.6054286  0.6054286  0.59607022 0.6054286  0.6054286\n",
      " 0.62284702 0.62284702        nan 0.62284702 0.62284702        nan\n",
      "        nan 0.58005098        nan 0.59258661 0.60657799 0.60657799\n",
      " 0.59612258 0.60657799 0.60657799 0.62284702 0.62284702        nan\n",
      " 0.62284702 0.62284702        nan        nan 0.61453604        nan\n",
      " 0.6276085  0.6204396  0.6204396  0.61936977 0.6204396  0.6204396\n",
      " 0.62284702 0.62284702        nan 0.62284702 0.62284702        nan\n",
      "        nan 0.62398984        nan 0.6228045  0.62284882 0.62284882\n",
      " 0.62282442 0.62284882 0.62284882 0.62284702 0.62284702        nan\n",
      " 0.62284702 0.62284702        nan        nan 0.62043853        nan\n",
      " 0.62043853 0.62164784 0.62164784 0.62164784 0.62164784 0.62164784\n",
      " 0.62284702 0.62284702        nan 0.62284702 0.62284702        nan\n",
      "        nan 0.62045345        nan 0.62045345 0.62164784 0.62164784\n",
      " 0.62164784 0.62164784 0.62164784 0.62284702 0.62284702        nan\n",
      " 0.62284702 0.62284702        nan        nan 0.62284702        nan\n",
      " 0.62284702 0.62284702 0.62284702 0.62284702 0.62284702 0.62284702]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid={\"C\":[0.001,.009,0.01,.09,1,5,10,25], \"penalty\":['none',\"l1\",\"l2\"],'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']} # l1 lasso l2 ridge\n",
    "\n",
    "\n",
    "tic = time.time()\n",
    "#training \n",
    "model = LogisticRegression(random_state = 0, max_iter=10000)\n",
    "logreg_cv = GridSearchCV(model,grid,cv=5, scoring = MCC_scorer)\n",
    "logreg_cv.fit(X_train,y_train)\n",
    "\n",
    "tac = time.time()\n",
    "\n",
    "running_time = tac-tic\n",
    "\n",
    "\n",
    "print(\"tuned hyperparameters :(best parameters) \",logreg_cv.best_params_)\n",
    "print(\"MCC :\",logreg_cv.best_score_)\n",
    "print(f'Running time: {running_time}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7097d9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.617671111800624"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using parameters after fine tuning \n",
    "best_estimator = logreg_cv.best_estimator_\n",
    "matthews_corrcoef(best_estimator.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86aa5cd2",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cd07d2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# rerun after XG-Boost\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(columns = [ 'hall_add_aggr','stim_add_aggr', 'depr_add_aggr','depr_woa_add_aggr','hall_woc_add_aggr'], axis=1), \n",
    "                                                    data[dt], test_size=0.3, random_state=0)\n",
    "\n",
    "oversample = SMOTE()\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "#y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d89ca045",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 1000, max_features = 'log2', criterion='gini')\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cont = rf.predict(X_test)\n",
    "\n",
    "y_pred = [1 if 0.5<i else 0 if i<1.3 else 2 for i in y_pred_cont] #convert to discrete variable 0.6 get the best acuracy\n",
    "\n",
    "#fig.savefig('../img/' + dt + 'confusion_matrix_stim_random_forest.png') just for the mid term report\n",
    "#y_pred_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "642895e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = {'auto', 'sqrt', 'log2'}\n",
    "criterion = {'gini', 'entropy'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "44b98f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC6: 0.6295428542018965\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 540x540 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MCC6 = matthews_corrcoef(y_test, y_pred)\n",
    "print(f\"MCC6: {MCC6}\")\n",
    "spec1=9\n",
    "\n",
    "\n",
    "cm1 = confusion_matrix(y_pred, y_test)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "ax.matshow(cm1, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(cm1.shape[0]):\n",
    "    for j in range(cm1.shape[1]):\n",
    "        ax.text(x=j, y=i,s=cm1[i, j], va='center', ha='center', size='xx-large')\n",
    "\n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix random forest', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765cbf72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
